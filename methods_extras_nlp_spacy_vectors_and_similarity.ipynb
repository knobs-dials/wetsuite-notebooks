{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities\n",
    "Most models add vectors to each token (tok2vec, or transformer-based for the _trf model),\n",
    "which are word embeddings, so should compare well for words with similar meaning.\n",
    "\n",
    "This assists tasks like calculating similarity of larger chunks of text as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "english_lg  = spacy.load('en_core_web_lg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869                                      ducks are great                                      cats are nice\n",
      "0.872                                      ducks are great                                     goats are cool\n",
      "0.796                                      ducks are great                                   Forks are spoons\n",
      "0.383                                      ducks are great                                   Forks and spoons\n",
      "0.450                                      ducks are great                        Forks and spoons and knives\n",
      "0.761                                      ducks are great                        Forks and spoons are knives\n",
      "0.868                     ducks and blah and blah and blah                    blue and bleh and bleh and bleh\n",
      "0.218                                                ducks                                               blue\n",
      "\n",
      "0.701  [Because it is smaller, the Moon has less gravity than Earth (only 1/6 of the amount on Earth).]  x  [So if a person weighs 60 kilograms on Earth, the person would only weigh 10 kilograms on the moon.[nb 2]]\n",
      "0.598  [So if a person weighs 60 kilograms on Earth, the person would only weigh 10 kilograms on the moon.[nb 2]]  x  [But even though the Moon's gravity is weaker than the Earth's gravity, it is still there.]\n",
      "0.764  [But even though the Moon's gravity is weaker than the Earth's gravity, it is still there.]  x  [If a person dropped a ball while standing on the moon, it would still fall down.]\n",
      "0.803  [If a person dropped a ball while standing on the moon, it would still fall down.]  x  [          However, it would fall much more slowly.]\n",
      "0.763  [          However, it would fall much more slowly.]  x  [A person who jumped as high as possible on the moon would jump higher than on Earth, but still fall back to the ground.   ]\n",
      "0.815  [A person who jumped as high as possible on the moon would jump higher than on Earth, but still fall back to the ground.   ]  x  [Rome ceased to be the capital from the time of the division.]\n",
      "0.687  [Rome ceased to be the capital from the time of the division.]  x  [In 286, the capital of the Western Roman Empire became Mediolanum (now Milan).]\n",
      "0.737  [In 286, the capital of the Western Roman Empire became Mediolanum (now Milan).]  x  [In 402, the capital was again moved, this time to Ravenna.]\n",
      "0.911  [In 402, the capital was again moved, this time to Ravenna.]  x  [In AD 398, Alaric led the Visigoths and began making attacks closer and closer to the capital.]\n",
      "0.743  [In AD 398, Alaric led the Visigoths and began making attacks closer and closer to the capital.]  x  [                   By 410, he had sacked the Rome.]\n",
      "0.752  [                   By 410, he had sacked the Rome.]  x  [            In 455, the Vandals captured the city.]\n",
      "0.973  [            In 455, the Vandals captured the city.]  x  [            In 476, the Goths captured the capital]\n"
     ]
    }
   ],
   "source": [
    "# You can generally compare any token/span (spans/sentence/docs will act as their average) using .similarity(). \n",
    "# \n",
    "# There are some fundamental limitations to this to keep in mind, like \n",
    "# - that it does not consider ordering, just words' presence\n",
    "# - how volatile the meaning of short sentences may be\n",
    "# - how function words dilute larger-span vectors (and might make them compare well for non-contentful reasons)\n",
    "# - 'static vectors' basically means a word has the same vector in all contexts.\n",
    "\n",
    "for one, other in (\n",
    "        ('ducks are great', 'cats are nice'),\n",
    "        ('ducks are great', 'goats are cool'),\n",
    "        ('ducks are great', 'Forks are spoons'),\n",
    "        ('ducks are great', 'Forks and spoons'),\n",
    "        ('ducks are great', 'Forks and spoons and knives'),\n",
    "        ('ducks are great', 'Forks and spoons are knives'),\n",
    "        ('ducks and blah and blah and blah', 'blue and bleh and bleh and bleh'),\n",
    "        ('ducks',           'blue'),\n",
    "    ):\n",
    "    sim = english_lg( one ).similarity(english_lg( other ))\n",
    "    print( \"%.3f   %50s %50s\"%( sim, one, other ))\n",
    "\n",
    "# These three-world phrases are actually quite contrived - real sentences have a narrower range of \n",
    "\n",
    "print()\n",
    "text = \"\"\"Because it is smaller, the Moon has less gravity than Earth (only 1/6 of the amount on Earth). So if a person weighs 60 kilograms on Earth, the person would only weigh 10 kilograms on the moon.[nb 2] But even though the Moon's gravity is weaker than the Earth's gravity, it is still there. If a person dropped a ball while standing on the moon, it would still fall down. However, it would fall much more slowly. A person who jumped as high as possible on the moon would jump higher than on Earth, but still fall back to the ground.   Rome ceased to be the capital from the time of the division. In 286, the capital of the Western Roman Empire became Mediolanum (now Milan). In 402, the capital was again moved, this time to Ravenna. In AD 398, Alaric led the Visigoths and began making attacks closer and closer to the capital. By 410, he had sacked the Rome. In 455, the Vandals captured the city. In 476, the Goths captured the capital \"\"\"\n",
    "doc = english_lg( text )\n",
    "sents = list(doc.sents)\n",
    "for i in range(len(sents)-1):\n",
    "    one, other = sents[i], sents[i+1] \n",
    "    sim = one.similarity( other )\n",
    "    print( \"%.3f  [%50s]  x  [%50s]\"%( sim, one, other ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Spacy has, however, made things a bit complex.\n",
    "- _sm models don't have vectors.  While similarity() still does something useful at all, you should assume this is extremely basic.\n",
    "- _md and _lg  models tend to have static word vectors, meaning a word will receive the same vector in all contexts (e.g. for english it's the GroVe )\n",
    "- _trf do context sensitive embeddings (and put those values in a different place)\n",
    "\n",
    "This means that similarity() doesn't just pick up vectors -- its implementation will easily vary between models.\n",
    "\n",
    "It also means you should _not_ assume you can use the vectors directly, \n",
    "though you can get away with it if you stick to one model.\n",
    "\n",
    "\n",
    "Note that\n",
    "- scores on spans and docs act as the average of their compobnents\n",
    "- ...which also means e.g. function words can dilute larger-span vectors (and might make them compare well for non-contentful reasons)\n",
    "- (...so...) similarity() does not consider ordering, just words' presence\n",
    "- shorter sentences have minimal and more volative meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install spacy\n",
    "\n",
    "!python3 -m spacy download en_core_web_trf   # works better, but can be rather slow without GPU properly set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_core_web_trf' (3.4.1) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "english_trf = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding transformer based similarity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'tensor2attr' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/var/www/coding/wetsuite/notebooks/examples/nlp_spacy_vectors_and_similarity.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e3137382e323139222c2275736572223a227363617266626f79227d/var/www/coding/wetsuite/notebooks/examples/nlp_spacy_vectors_and_similarity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m english_trf\u001b[39m.\u001b[39mhas_pipe(\u001b[39m'\u001b[39m\u001b[39mtensor2attr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e3137382e323139222c2275736572223a227363617266626f79227d/var/www/coding/wetsuite/notebooks/examples/nlp_spacy_vectors_and_similarity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39madding transformer based similarity\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e3137382e323139222c2275736572223a227363617266626f79227d/var/www/coding/wetsuite/notebooks/examples/nlp_spacy_vectors_and_similarity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     english_trf\u001b[39m.\u001b[39;49madd_pipe(\u001b[39m'\u001b[39;49m\u001b[39mtensor2attr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/language.py:786\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    782\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[1;32m    783\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[1;32m    784\u001b[0m     )\n\u001b[1;32m    785\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[1;32m    787\u001b[0m         factory_name,\n\u001b[1;32m    788\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    789\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    790\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m    791\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    792\u001b[0m     )\n\u001b[1;32m    793\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/language.py:660\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    653\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    654\u001b[0m         name\u001b[39m=\u001b[39mfactory_name,\n\u001b[1;32m    655\u001b[0m         opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m         lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[1;32m    659\u001b[0m     )\n\u001b[0;32m--> 660\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[1;32m    661\u001b[0m pipe_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n\u001b[1;32m    662\u001b[0m \u001b[39m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'tensor2attr' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "# while _trf can do contextual word embedding rather than static word embedding, this is not placed in .vector.tensors\n",
    "# You could fish out the tensors like   toks_vectors, doc_vector = doc._.trf_data.tensors\n",
    "#   but it's handier to augent spacy to make similarity work with transformer tensors - custom pipeline element defined in our helper module\n",
    "\n",
    "# this mentioned tensor2attr is not basic spacy, it exists because it is defined in our helpers_spacy\n",
    "if not english_trf.has_pipe('tensor2attr'):\n",
    "    print(\"adding transformer based similarity\")\n",
    "    english_trf.add_pipe('tensor2attr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named spacy.tokens",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e483129e3b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named spacy.tokens"
     ]
    }
   ],
   "source": [
    "import spacy.tokens\n",
    "spacy.tokens.Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3868950/4012342059.py:13: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  sim = english_trf( one ).similarity(english_trf( other ))\n",
      "/tmp/ipykernel_3868950/4012342059.py:13: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  sim = english_trf( one ).similarity(english_trf( other ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000                                      ducks are great                                      cats are nice\n",
      "0.000                                      ducks are great                                     goats are cool\n",
      "0.000                                      ducks are great                                   Forks are spoons\n",
      "0.000                                      ducks are great                                   Forks and spoons\n",
      "0.000                                      ducks are great                        Forks and spoons and knives\n",
      "0.000                                      ducks are great                        Forks and spoons are knives\n",
      "0.000                     ducks and blah and blah and blah                    blue and bleh and bleh and bleh\n",
      "0.000                                                ducks                                               blue\n",
      "\n",
      "0.000  [Because it is smaller, the Moon has less gravity than Earth (only 1/6 of the amount on Earth).] x [So if a person weighs 60 kilograms on Earth, the person would only weigh 10 kilograms on the moon.[nb 2]]\n",
      "0.000  [So if a person weighs 60 kilograms on Earth, the person would only weigh 10 kilograms on the moon.[nb 2]] x [But even though the Moon's gravity is weaker than the Earth's gravity, it is still there.]\n",
      "0.000  [But even though the Moon's gravity is weaker than the Earth's gravity, it is still there.] x [If a person dropped a ball while standing on the moon, it would still fall down.]\n",
      "0.000  [If a person dropped a ball while standing on the moon, it would still fall down.] x [          However, it would fall much more slowly.]\n",
      "0.000  [          However, it would fall much more slowly.] x [A person who jumped as high as possible on the moon would jump higher than on Earth, but still fall back to the ground.]\n",
      "0.000  [A person who jumped as high as possible on the moon would jump higher than on Earth, but still fall back to the ground.] x [Because the Moon has no atmosphere, there is no air resistance, so a feather will fall as fast as a hammer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3868950/4012342059.py:22: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  sim = one.similarity( other )\n",
      "/tmp/ipykernel_3868950/4012342059.py:22: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  sim = one.similarity( other )\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = english_trf(\"The bank stores investment capital in Paris, the capital of France\")\n",
    "first_capital, second_capital = doc[4], doc[9]\n",
    "print( first_capital, second_capital, round( first_capital.similarity(second_capital), 2) ) \n",
    "# without contextual word embeddings, both capitals would be the same, and their similarity 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out what word it's close to\n",
    "money  = english_trf(\"money\")[0]\n",
    "city   = english_trf(\"city\")[0]\n",
    "paris  = english_trf(\"lyon\")[0]\n",
    "\n",
    "print ('              ','money', 'city', 'lyon')\n",
    "for in_sent, example in ( (' bank_capital ',first), ('city_capital',second) ):\n",
    "    print( '%15s %4.2f %4.2f %4.2f'%(in_sent, round(example.similarity(money), 2), round( example.similarity(city), 2), round( example.similarity(paris), 2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#vocablist = list(english_lg.vocab.strings)\n",
    "vvv = []\n",
    "i=0\n",
    "for string in list(english_lg.vocab.strings)[::10]:\n",
    "    if len(string)<4:\n",
    "        continue\n",
    "    n = english_lg(string)[0].norm\n",
    "    if n > 800000000000000000:\n",
    "        continue\n",
    "\n",
    "    print( n, string, english_lg.vocab.strings[string])\n",
    "    \n",
    "    if string in english_lg.vocab.vectors:\n",
    "        print( string, english_lg.vocab.strings[string], numpy.abs(english_lg.vocab.vectors[string]))\n",
    "    \n",
    "    vvv.append( string )\n",
    "\n",
    "    i+=1\n",
    "    if i>1000:\n",
    "        break\n",
    "print(i)\n",
    "print(len(vvv))\n",
    "\n",
    "vocablist = vvv\n",
    "\n",
    "#english_lg.vocab.lookups\n",
    "#for string in \n",
    "#print(len(vocablist))\n",
    "#vocablist[0].prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english_md = spacy.load(\"en_core_web_md\")   \n",
    "\n",
    "allsim1, allsim2 = {}, {}\n",
    "#vocablist = list(english_lg.vocab.strings)\n",
    "\n",
    "print( len(vocablist) )\n",
    "\n",
    "for word in vocablist[::10]:\n",
    "    isolated = english_trf(word)\n",
    "    allsim1[word] = first_capital.similarity( isolated )\n",
    "    allsim2[word] = second_capital.similarity( isolated )\n",
    "\n",
    "allsim1 = list(allsim1.items())\n",
    "allsim1.sort(key = lambda x:x[1], reverse=True)\n",
    "print( allsim1[:10] )\n",
    "\n",
    "allsim2 = list(allsim2.items())\n",
    "allsim2.sort(key = lambda x:x[1], reverse=True)\n",
    "print( allsim2[:10] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things like 'find similar words within texts' will rely on some variant of 'compare everything to everything'\n",
    "# I've not found a spacy way to do such mass comparisons other than to call .similarity() a lot, which is a bunch of overhead\n",
    "# Since it seems to just be cosine similarity, we can use scipy to do a lot more comparisons in one go - code for which is in our helper\n",
    "\n",
    "print( \"SENTENCE SIMILARITY\" )\n",
    "for score, one, two in helpers_spacy.similar_sentences(doc,     thresh=0.5, n=5):   # yes, these these thresholds are chosen to give good results with this example. Play with them to see how messy it actually is.\n",
    "    print( \"    %5.2f  %40r  %40r\"%(score, one, two) )\n",
    "    \n",
    "print( \"TOKEN SIMILARITY\" )\n",
    "for score, one, two in helpers_spacy.similar_chunks(doc, 1,0,0, thresh=0.6, n=5):\n",
    "    print( \"    %5.2f  %40s  %40s\"%(score, one, two) )\n",
    "\n",
    "print( \"ENTITY AND NOUN CHUNK SIMILARITY\" )\n",
    "for score, one, two in helpers_spacy.similar_chunks(doc, 0,1,1, thresh=0.7, n=5):\n",
    "    print( \"    %5.2f  %40s  %40s\"%(score, one, two) )\n",
    "\n",
    "# It's generally not so useful to compare tokens with phrases from the same document, in that the top similarities will be phrases with their own head/root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the average of a sentence or document would be a lot of function words, \n",
    "#   direct comparison would still work but be watered down depending on how many of those there are\n",
    "\n",
    "\n",
    "\n",
    "#   so you might like \n",
    "# At the same time, spacy prefers its parsed object immutable, so you would have to work around it\n",
    "import numpy\n",
    "from importlib import reload\n",
    "reload(helpers_spacy)\n",
    "for sent in paris.sents:\n",
    "    print( '-'*80 )\n",
    "    print( sent )\n",
    "    sg = helpers_spacy.interesting_words( sent )\n",
    "    print( sg )\n",
    "    vpt = helpers_spacy.vector_per_tag(sent, average=True) \n",
    "    for tag, ary in vpt.items():\n",
    "        print( tag, numpy.linalg.norm(ary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
